{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd7a9c2",
   "metadata": {},
   "source": [
    "# Loss versus Robustness tradeoffs -- Plots\n",
    "\n",
    "This notebook is used to generate Figure 5 of the paper \"Robust Consensus in Ranking Data Analysis: Definitions, Properties and Computational Issues\"\n",
    "\n",
    "The fist cells load the relevant librairies and define the relevant functions.\n",
    "\n",
    "The next cells load the results.\n",
    "\n",
    "The last cell outputs the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215cc9e",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from app.launcher_classic import torch_dist, proba_plackett_luce, pairwise_matrix\n",
    "from app.launcher_classic import plot_end_training as plot_end_training_classic\n",
    "from app.launcher_classic import torch_dist as torch_dist_classic\n",
    "\n",
    "device = \"cpu\"\n",
    "default_tensor_type = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797edb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3e3a6",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e36ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_exp(dist, w, delta, epochs, dist_type_sym, norm_type, prefix=\"\", folder_path=None):\n",
    "    if folder_path == None:\n",
    "        folder_path = f\"{os.getcwd()}/perf_robustness_profile/\"+prefix\n",
    "    filename = f\"perf_robustness_dist={dist}_w={w}_delta={delta}_epochs={epochs}_dist_type_sym={dist_type_sym}_norm_L{norm_type}.pt\"\n",
    "    return folder_path+filename\n",
    "\n",
    "def get_res(mypath, dist, torch_all_ranks, plot_training=False, n=4, choose_val=\"full\"):\n",
    "    \n",
    "    perf_list, eps_list1, eps_list2, alt_eps_list1, alt_eps_list2, thresholds = load_plot_exp(mypath, dist, torch_all_ranks, plot_training=plot_training, n=n)\n",
    "    \n",
    "    print(f\"perf_list = {perf_list} \\n\\n eps_list1 (l1 norm) = {eps_list1}  \\n eps_list2 (l2 norm) = {eps_list2} \\n\\n alt_eps_list1 (l1 norm) = {alt_eps_list1}  \\n alt_eps_list2 (l2 norm) = {alt_eps_list2} \\n\\n\")\n",
    "    \n",
    "    l1_norm = list()\n",
    "    for i in range(len(eps_list1)):\n",
    "        minval = torch.min( torch.tensor(eps_list1[i]), torch.tensor(alt_eps_list1[i]) ) \n",
    "        maxval = torch.max( torch.tensor(eps_list1[i]), torch.tensor(alt_eps_list1[i]) ) \n",
    "        if choose_val == \"full\":\n",
    "            l1_norm.append(torch.tensor(eps_list1[i]))\n",
    "        elif choose_val == \"alt\":\n",
    "            l1_norm.append(torch.tensor(alt_eps_list1[i]))\n",
    "        elif choose_val == \"min\":\n",
    "            l1_norm.append(minval)\n",
    "        elif choose_val == \"max\":\n",
    "            l1_norm.append(maxval)\n",
    "\n",
    "    l2_norm = list()\n",
    "    for i in range(len(eps_list2)):\n",
    "        minval = torch.min( torch.tensor(eps_list2[i]), torch.tensor(alt_eps_list2[i]) ) \n",
    "        maxval = torch.max( torch.tensor(eps_list2[i]), torch.tensor(alt_eps_list2[i]) ) \n",
    "        if choose_val == \"full\":\n",
    "            l2_norm.append(torch.tensor(eps_list2[i]))\n",
    "        elif choose_val == \"alt\":\n",
    "            l2_norm.append(torch.tensor(alt_eps_list2[i]))\n",
    "        elif choose_val == \"min\":\n",
    "            l2_norm.append(minval)\n",
    "        elif choose_val == \"max\":\n",
    "            l2_norm.append(maxval)\n",
    "    \n",
    "    return perf_list, l1_norm, l2_norm\n",
    "\n",
    "def load_plot_exp(path, dist, torch_all_ranks, plot_training=False, n=4):\n",
    "    dict_res = torch.load(path)\n",
    "    training_dict = dict_res['training_dict']\n",
    "    final_val_dict = dict_res['final_val_dict']\n",
    "    epochs = int(path.split('epochs=')[1].split('_')[0])\n",
    "    p_torch=final_val_dict['p_torch']\n",
    "    print(f\"PTORCh = {p_torch}\")\n",
    "    \n",
    "    for i, threshold in enumerate(training_dict.keys()):\n",
    "        qlist_ = training_dict[threshold]['qs_'][epochs-10000:]\n",
    "        q1 = np.mean(qlist_, axis=0)\n",
    "        q2 = training_dict[threshold]['mean_qs'][-1]\n",
    "        p_torch=final_val_dict['p_torch']\n",
    "    \n",
    "    if plot_training:\n",
    "        for threshold in list(training_dict.keys()):\n",
    "            if type_ == \"classic\":\n",
    "                dist_Tp_Tq = lambda _p,_q: torch_dist_classic(dist, _p, _q, torch_all_ranks, threshold=threshold, dist_type_sym=dist_type_sym)\n",
    "            elif type_ == \"pairwise\":\n",
    "                dist_Tp_Tq = lambda _P,_Q: torch_dist_pairwise(dist, _P, _Q, torch_all_ranks, threshold=threshold, dist_type_sym=dist_type_sym)\n",
    "            \n",
    "            norms_ = training_dict[threshold]['norms']\n",
    "            losses = training_dict[threshold]['losses']\n",
    "            mean_qs_=training_dict[threshold]['mean_qs']\n",
    "            phis_=training_dict[threshold]['phis']\n",
    "            mean_phi2_=training_dict[threshold]['mean_phi2']\n",
    "            lambdas_=training_dict[threshold]['lambdas']\n",
    "            mean_lambdas_=training_dict[threshold]['mean_lambdas']\n",
    "            grad_data=training_dict[threshold]['grad_data']\n",
    "            freq_phi_=training_dict[threshold]['freq_phi']\n",
    "            p_torch=final_val_dict['p_torch']\n",
    "            print(f\"load plot n = {n}, ptorch = {p_torch.shape}, all ranks = {torch_all_ranks.shape}\")\n",
    "            P=pairwise_matrix(p_torch, torch_all_ranks, n=n)\n",
    "            \n",
    "            plot_end_training_classic(p_torch=p_torch, dist_Tp_Tq=dist_Tp_Tq, norms_=norms_, losses=losses, mean_qs_=mean_qs_, phis_=phis_, mean_phi2_=mean_phi2_, lambdas_=lambdas_, mean_lambdas_=mean_lambdas_, grad_data=grad_data, norm_type=norm_type)\n",
    "    return final_val_dict[\"perf_list\"], final_val_dict[\"eps_list1\"], final_val_dict[\"eps_list2\"], final_val_dict[\"alt_eps_list1\"], final_val_dict[\"alt_eps_list2\"], final_val_dict[\"thresholds\"]\n",
    "\n",
    "def get_pair_results(my_paths, dists, torch_all_ranks, plot_training=False, n=4, choose_val=\"full\", thresholds=np.linspace(0,0.5,11)):\n",
    "    \n",
    "    perf_list_res = list()\n",
    "    l1_norm_res = list()\n",
    "    \n",
    "    for i, (my_path, dist) in enumerate(zip(my_paths, dists)):\n",
    "        print(f\"File path = {my_path}\")\n",
    "        perf_list, l1_norm, l2_norm = get_res(my_path, dist, torch_all_ranks, plot_training=plot_training, n=n, choose_val=choose_val)\n",
    "        perf_res_ = perf_list[0]/(n*(n-1)/2)\n",
    "        l1_norm_res_ = l1_norm[0].item()/2\n",
    "        print(f\"Results: perf = {perf_res_} and robustness = {l1_norm_res_}\")\n",
    "        perf_list_res.append(perf_res_)\n",
    "        l1_norm_res.append(l1_norm_res_)\n",
    "    \n",
    "    return perf_list_res, l1_norm_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219b877",
   "metadata": {},
   "source": [
    "### Load experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = 4\n",
    "all_ranks = list(itertools.permutations(list(np.arange(n_items))))\n",
    "all_ranks = [np.array(elem) for elem in all_ranks]\n",
    "torch_all_ranks = torch.from_numpy(np.asarray(all_ranks))\n",
    "\n",
    "# Unchanged parameters\n",
    "delta = 1\n",
    "dist_type_sym = False\n",
    "norm_type = \"1\"\n",
    "choose_val = \"full\"\n",
    "thresholds = np.array([0.05])\n",
    "dists = [\"erm\", \"maxpair\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30a759",
   "metadata": {},
   "source": [
    "##### Random Plackett-Luce 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the exp --> You will need to change \"epochs\" and \"w\" in the next cell\n",
    "# %run app/launcher_classic.py --seed_vals \"18\" --epochs_list \"20000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic (mostly unchanged) parameters\n",
    "epochs = 20001\n",
    "prefix = \"unimodal/\"\n",
    "n_items = 4\n",
    "\n",
    "# To copy paste from the name of the saved file\n",
    "w = f\"[1.1173979 1.0336659 0.6316072 0.3937561]\"\n",
    "\n",
    "my_paths = [get_path_exp(dist, w, delta, epochs, dist_type_sym, norm_type, prefix=prefix) for dist in dists]\n",
    "perf_18, tv_dist_18 = get_pair_results(my_paths, dists, torch_all_ranks, plot_training=False, n=4, thresholds=np.linspace(0,0.5,11), choose_val=choose_val)\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1872f",
   "metadata": {},
   "source": [
    "##### Random Plackett-Luce 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec11958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the exp --> You will need to change \"epochs\" and \"w\" in the next cell\n",
    "# %run app/launcher_classic.py --seed_vals \"283\" --epochs_list \"20000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c9dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic (mostly unchanged) parameters\n",
    "epochs = 20001\n",
    "prefix = \"unimodal/\"\n",
    "\n",
    "# To copy-paste from the name of the file\n",
    "w = f\"[1.7226691  0.6500638  0.09824223 0.09391503]\"\n",
    "\n",
    "my_paths = [get_path_exp(dist, w, delta, epochs, dist_type_sym, norm_type, prefix=prefix) for dist in dists]\n",
    "perf_283, tv_dist_283 = get_pair_results(my_paths, dists, torch_all_ranks, plot_training=False, n=4, thresholds=np.linspace(0,0.5,11), choose_val=choose_val)\n",
    "print(perf_283, tv_dist_283)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28e813",
   "metadata": {},
   "source": [
    "##### Random Plackett-Luce 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b642f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the exp --> You will need to change \"epochs\" and \"w\" in the next cell\n",
    "# %run app/launcher_classic.py --seed_vals \"1903\" --epochs_list \"20000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic (mostly unchanged) parameters\n",
    "epochs = 20001\n",
    "prefix = \"unimodal/\"\n",
    "\n",
    "# To copy-paste from the name of the file\n",
    "w = f\"[2.7095466 1.1030647 0.98387283 0.3974442]\"\n",
    "\n",
    "my_paths = [get_path_exp(dist, w, delta, epochs, dist_type_sym, norm_type, prefix=prefix) for dist in dists]\n",
    "perf_1903, tv_dist_1903 = get_pair_results(my_paths, dists, torch_all_ranks, plot_training=False, n=4, thresholds=np.linspace(0,0.5,11), choose_val=choose_val)\n",
    "print(perf_1903, tv_dist_1903)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c65e3d",
   "metadata": {},
   "source": [
    "##### Bucket 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea021f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the exp\n",
    "# %run app/launcher_classic.py --seed_vals \"279\" --exp_types \"two_untied\" --epochs_list \"20000\" --gap_mode \"0.01\" --mixture_val \"0.95\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic (mostly unchanged) parameters\n",
    "epochs = 20001\n",
    "prefix = \"two_untied/\"\n",
    "\n",
    "w = \"two_untied_mix=0.95_gap=0.01_seed=279\"\n",
    "\n",
    "my_paths = [get_path_exp(dist, w, delta, epochs, dist_type_sym, norm_type, prefix=prefix) for dist in dists]\n",
    "perf_bucket_001, tv_dist_bucket_001 = get_pair_results(my_paths, dists, torch_all_ranks, plot_training=False, n=4, thresholds=thresholds, choose_val=choose_val)\n",
    "print(perf_bucket_001, tv_dist_bucket_001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f888fa",
   "metadata": {},
   "source": [
    "##### Bucket 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the exp\n",
    "# %run app/launcher_classic.py --seed_vals \"279\" --exp_types \"two_untied\" --epochs_list \"20000\" --gap_mode \"0.1\" --mixture_val \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic (mostly unchanged) parameters\n",
    "epochs = 20001\n",
    "prefix = \"two_untied/\"\n",
    "\n",
    "w = \"two_untied_mix=1_gap=0.1_seed=279\"\n",
    "\n",
    "my_paths = [get_path_exp(dist, w, delta, epochs, dist_type_sym, norm_type, prefix=prefix) for dist in dists]\n",
    "perf_bucket_01, tv_dist_bucket_01 = get_pair_results(my_paths, dists, torch_all_ranks, plot_training=False, n=4, thresholds=thresholds, choose_val=choose_val)\n",
    "print(perf_bucket_01, tv_dist_bucket_01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931deda",
   "metadata": {},
   "source": [
    "##### Almost uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the exp\n",
    "# %run app/launcher_classic.py --seed_vals \"279\" --ms \"0.01\" --epochs_list \"20000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic (mostly unchanged) parameters\n",
    "epochs = 20001\n",
    "prefix = \"unimodal/\"\n",
    "\n",
    "w = f\"[0.99852407 0.9910795  0.9796387  0.97639084]\"\n",
    "\n",
    "my_paths = [get_path_exp(dist, w, delta, epochs, dist_type_sym, norm_type, prefix=prefix) for dist in dists]\n",
    "perf_uniform, tv_dist_uniform = get_pair_results(my_paths, dists, torch_all_ranks, plot_training=False, n=4, thresholds=thresholds, choose_val=choose_val)\n",
    "print(perf_uniform, tv_dist_uniform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf8394",
   "metadata": {},
   "source": [
    "##### Almost point mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d70b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun the exp\n",
    "# %run app/launcher_classic.py --seed_vals \"279\" --ms \"10\" --epochs_list \"20000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic (mostly unchanged) parameters\n",
    "delta = 1\n",
    "epochs = 20002\n",
    "prefix = \"unimodal/\"\n",
    "\n",
    "w = f\"[2.2831823e-01 1.2837668e-04 1.1639423e-09 4.2043390e-11]\"\n",
    "\n",
    "my_paths = [get_path_exp(dist, w, delta, epochs, dist_type_sym, norm_type, prefix=prefix) for dist in dists]\n",
    "perf_dirac, tv_dist_dirac = get_pair_results(my_paths, dists, torch_all_ranks, plot_training=False, n=4, thresholds=thresholds, choose_val=choose_val)\n",
    "print(perf_dirac, tv_dist_dirac)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7638e",
   "metadata": {},
   "source": [
    "### Generate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c37aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = plt.cm.get_cmap('Reds')\n",
    "myred = cm(1/2)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    'text.latex.preamble': r'\\usepackage{amsfonts}'\n",
    "        })\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "\n",
    "median_res_x = [perf_18[0], perf_283[0], perf_1903[0], perf_bucket_001[0], perf_bucket_01[0], perf_uniform[0], perf_dirac[0]]\n",
    "median_res_y = [tv_dist_18[0], tv_dist_283[0], tv_dist_1903[0], tv_dist_bucket_001[0], tv_dist_bucket_01[0], tv_dist_uniform[0], tv_dist_dirac[0]]\n",
    "\n",
    "maxpair_res_x = [perf_18[1], perf_283[1], perf_1903[1], perf_bucket_001[1], perf_bucket_01[1], perf_uniform[1], perf_dirac[1]]\n",
    "maxpair_res_y = [tv_dist_18[1], tv_dist_283[1], tv_dist_1903[1], tv_dist_bucket_001[1], tv_dist_bucket_01[1], tv_dist_uniform[1], tv_dist_dirac[1]]\n",
    "\n",
    "plt.plot(perf_18, tv_dist_18, \"-\", c=\"black\")\n",
    "plt.plot(perf_283, tv_dist_283, \"-\", c=\"black\")\n",
    "plt.plot(perf_1903, tv_dist_1903, \"-\", c=\"black\")\n",
    "plt.plot(perf_bucket_001, tv_dist_bucket_001, \"-\", c=\"black\")\n",
    "plt.plot(perf_bucket_01, tv_dist_bucket_01, \"-\", c=\"black\")\n",
    "plt.plot(perf_uniform, tv_dist_uniform, \"-\", c=\"black\")\n",
    "plt.plot(perf_dirac, tv_dist_dirac, \"-\", c=\"black\")\n",
    "\n",
    "plt.scatter(median_res_x, median_res_y, s=120, c=\"cornflowerblue\", marker=\"x\", label=\"Kemeny's median\")\n",
    "plt.scatter(maxpair_res_x, maxpair_res_y, s=90, c=myred, marker=\"o\", label=r\"Down. Merge ($t=0.05$)\")\n",
    "plt.xlabel(r\"Loss $\\mathbb{E}_p(d_{\\tau}(T(p), \\Sigma))$\", fontsize=14)\n",
    "plt.ylabel(r\"Robustness at level $1: \\hat{\\varepsilon}^{\\gamma}_{p,T}(1)$\", fontsize=14)\n",
    "plt.title(f\"Loss vs Robustness Tradeoff\", fontsize=15)\n",
    "legend = plt.legend(title=\"Legend\", fontsize=12)\n",
    "legend.get_title().set_fontsize('13')\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.xlim((-0.02, 0.52))\n",
    "plt.ylim((-0.03, 1.03))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
